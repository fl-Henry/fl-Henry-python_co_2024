# Занятие 5: Работа с структурой объектов pandas. Чтение и запись данных.

## 1. Добавление и удаление данных

Работа с данными в pandas включает не только их анализ и обработку, но и управление структурой DataFrame. Это подразумевает добавление новых данных и удаление ненужных. 

### Добавление столбцов

Добавление нового столбца в DataFrame — это одна из самых простых операций. Вы можете создать новый столбец, просто присвоив ему значения.

**Пример:**
```python
import pandas as pd

# Создаем пример DataFrame
data = {'A': [1, 2, 3], 'B': [4, 5, 6]}
df = pd.DataFrame(data)

# Добавляем новый столбец 'C'
df['C'] = df['A'] + df['B']
```
В этом примере новый столбец 'C' будет содержать сумму значений из столбцов 'A' и 'B'. 

### Добавление строк

Добавление строк в DataFrame является важной частью работы с данными в pandas. Существует несколько способов это сделать, в зависимости от контекста и структуры ваших данных.

#### Добавление одной строки

Для добавления одной строки можно использовать метод `loc[]` или `iloc[]`, а также функцию `append()`. Однако стоит отметить, что метод `append()` устаревает, и рекомендуется использовать `pd.concat()`.

**Использование `loc[]`**

С помощью `loc[]` вы можете добавлять строку, указывая новый индекс.

**Пример:**
```python
import pandas as pd

# Создаем пример DataFrame
data = {'A': [1, 2, 3], 'B': [4, 5, 6]}
df = pd.DataFrame(data)

# Добавляем новую строку
df.loc[len(df)] = [4, 7]  # Индекс новой строки будет равен текущей длине DataFrame
```
В этом примере мы добавили строку с индексом 3, указав значения для столбцов 'A' и 'B'.

**B. Использование `pd.concat()`**

Для добавления строки также можно использовать `pd.concat()`, что предпочтительно в современных версиях pandas.

**Пример:**
```python
# Создаем новую строку в виде Series
new_row = pd.Series({'A': 4, 'B': 7})

# Используем concat для добавления новой строки
df = pd.concat([df, new_row.to_frame().T], ignore_index=True)
```
В этом случае мы создаем новую строку в виде Series и добавляем её к существующему DataFrame, преобразовав в DataFrame с помощью `to_frame()` и транспонировав с помощью `.T`.

#### Добавление нескольких строк

Если вам нужно добавить несколько строк, вы можете создать DataFrame, представляющий новые строки, и объединить его с существующим.

**Пример:**
```python
# Создаем DataFrame с новыми строками
new_rows = pd.DataFrame({'A': [5, 6], 'B': [8, 9]})

# Объединяем DataFrame
df = pd.concat([df, new_rows], ignore_index=True)
```
Здесь мы создаем новый DataFrame с несколькими строками и объединяем его с исходным DataFrame. Параметр `ignore_index=True` позволяет сбросить индексы.

#### Использование `DataFrame.append()`

Хотя метод `append()` устаревает, его можно использовать для быстрого добавления строк в более старых версиях pandas. Однако в новых версиях рекомендуется переходить на `pd.concat()`.

**Пример:**
```python
# Добавление одной строки с использованием append
df = df.append({'A': 7, 'B': 10}, ignore_index=True)
```
Этот способ позволяет добавлять строки, передавая словарь значений. Однако, как уже упоминалось, `append()` не рекомендуется использовать в новых проектах.

### Удаление данных

#### Удаление столбцов
Удаление столбца можно выполнить с помощью метода `drop()`. Этот метод позволяет удалить один или несколько столбцов, указав их имена.

**Пример:**
```python
# Удаляем столбец 'C'
df = df.drop(columns=['C'])
```
В этом случае мы удаляем столбец 'C'. Обратите внимание, что `drop()` по умолчанию возвращает новый DataFrame, и исходный DataFrame остается неизменным, если не использовать параметр `inplace=True`.

#### Удаление строк
Удаление строк также можно выполнить с помощью `drop()`, указав индекс строки, которую нужно удалить. Если хотите удалить строки по условию, можно использовать фильтрацию.

**Пример:**
```python
# Удаляем строку с индексом 1
df = df.drop(index=1)
```
Или для удаления по условию:
```python
# Удаляем строки, где значение в столбце 'A' меньше 3
df = df[df['A'] >= 3]
```
Здесь мы фильтруем DataFrame, оставляя только те строки, где значение в столбце 'A' больше или равно 3.

## 2. Объединение объектов pandas

Объединение объектов в pandas позволяет комбинировать данные из разных DataFrame в единый набор данных, что является важной задачей при анализе данных.

### Конкатенация

**Конкатенация** — это процесс соединения объектов вдоль заданной оси (обычно по строкам или столбцам). В pandas для этого используется функция `pd.concat()`.

- **Синтаксис:**
  ```python
  pd.concat(objs, axis=0, join='outer', ignore_index=False)
  ```
  - `objs`: Список или словарь объектов для объединения.
  - `axis`: Ось, по которой будет происходить конкатенация (0 — по строкам, 1 — по столбцам).
  - `join`: Способ объединения индексов ('outer' — по умолчанию, 'inner' — пересечение).
  - `ignore_index`: Сбрасывает индексы в итоговом DataFrame.

**Пример использования**

```python
import pandas as pd

# Создаем два DataFrame
df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})

# Конкатенация по строкам
result = pd.concat([df1, df2], axis=0)
```
В этом примере два DataFrame объединяются по строкам, в результате чего получается новый DataFrame, содержащий данные из обоих исходных DataFrame.

### Слияние

**Слияние** — это процесс комбинирования DataFrame по определенному ключу (или ключам). В pandas для этого используется метод `merge()`.

- **Синтаксис:**
  ```python
  pd.merge(left, right, how='inner', on=None)
  ```
  - `left`: Левый DataFrame для слияния.
  - `right`: Правый DataFrame для слияния.
  - `how`: Тип слияния ('inner', 'outer', 'left', 'right').
  - `on`: Ключ(и) для слияния.

**Пример использования**

```python
# Создаем два DataFrame для слияния
df1 = pd.DataFrame({'key': ['A', 'B'], 'value1': [1, 2]})
df2 = pd.DataFrame({'key': ['B', 'C'], 'value2': [3, 4]})

# Слияние по ключу
result = pd.merge(df1, df2, how='inner', on='key')
```
В данном примере DataFrame объединяются по столбцу 'key'. Результат будет содержать только те строки, где ключи совпадают (в данном случае — 'B').


### Объединение с помощью `join()`

Метод `join()` используется для объединения двух DataFrame на основе индексов.

- **Синтаксис:**
  ```python
  df1.join(df2, how='left', lsuffix='_left', rsuffix='_right')
  ```
  - `how`: Тип объединения ('left', 'right', 'outer', 'inner').
  - `lsuffix` и `rsuffix`: Суффиксы для идентификации столбцов с одинаковыми именами.

**Пример использования**

```python
# Создаем два DataFrame
df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
df2 = pd.DataFrame({'B': [5, 6]})

# Объединение по индексам
df = df1.join(df2, rsuffix='_df2')
```
В этом примере `join()` объединяет DataFrame по индексам, в результате чего мы получаем полный набор данных, включая все индексы из обоих DataFrame.


### Объединение с использованием `combine_first()`

Метод `combine_first()` позволяет объединять два DataFrame, заполняя пропуски значениями из другого DataFrame.

- **Синтаксис:**
  ```python
  df1.combine_first(df2)
  ```

**Пример использования**

```python
# Создаем два DataFrame с пропусками
df1 = pd.DataFrame({'A': [1, 2, None], 'B': [None, 5, 6]})
df2 = pd.DataFrame({'A': [None, None, 3], 'B': [4, None, None]})

# Объединение с заполнением пропусков
result = df1.combine_first(df2)
```
В этом случае `combine_first()` заполняет пропуски в `df1` значениями из `df2`, создавая итоговый DataFrame без пропусков.

## 3. Чтение данных

Чтение данных — это один из ключевых шагов в анализе данных, и pandas предлагает множество инструментов для импорта данных из различных источников. 

### Чтение из различных форматов

pandas поддерживает множество форматов файлов, включая CSV, Excel, JSON и другие. Это позволяет гибко работать с данными, независимо от их источника.

### Чтение данных из CSV

Чтение данных из CSV (Comma-Separated Values) является одним из самых распространенных способов работы с табличными данными в pandas. CSV файлы легко создавать и редактировать, и они поддерживаются многими приложениями. В этом разделе мы подробно рассмотрим, как использовать pandas для чтения данных из CSV файлов.

---

### I. Основы использования `pd.read_csv()`

Функция `pd.read_csv()` позволяет загружать данные из CSV файлов в DataFrame. Она обладает множеством параметров, которые можно использовать для настройки процесса чтения.

#### A. Синтаксис

```python
pd.read_csv(filepath_or_buffer, sep=',', header='infer', names=None, index_col=None, usecols=None, dtype=None, na_values=None, parse_dates=False, ...)
```

- **filepath_or_buffer:** Путь к файлу или URL, из которого нужно прочитать данные.
- **sep:** Разделитель, используемый в файле. По умолчанию это запятая (`,`).
- **header:** Указывает, какой ряд использовать в качестве заголовков. По умолчанию это первая строка.
- **names:** Список имен столбцов, которые будут использоваться, если заголовки отсутствуют.
- **index_col:** Столбец, который будет использоваться в качестве индекса.
- **usecols:** Список столбцов, которые необходимо загрузить.
- **dtype:** Указание типов данных для столбцов.
- **na_values:** Значения, которые будут интерпретироваться как NaN.
- **parse_dates:** Указывает, какие столбцы следует интерпретировать как даты.

**Пример**

```python
import pandas as pd

# Чтение данных из CSV файла
df = pd.read_csv('data.csv')
```
В этом примере мы загружаем данные из файла `data.csv` в DataFrame. pandas автоматически определяет разделитель и заголовки, если они присутствуют.

#### Чтение данных из Excel

Excel — еще один популярный формат, особенно в бизнесе. Для чтения данных из Excel файлов используем функцию `pd.read_excel()`.

- **Синтаксис:**
  ```python
  pd.read_excel(io, sheet_name=0, header=0, ...)
  ```

- **Пример:**
```python
# Чтение данных из Excel файла
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')
```
Здесь мы читаем данные из определенного листа Excel. По умолчанию загружается первый лист, если не указано иное.

### Чтение данных из JSON

JSON (JavaScript Object Notation) — это легкий формат обмена данными, который легко читается и пишется как людьми, так и машинами. Он часто используется для передачи структурированных данных между клиентом и сервером. В pandas чтение данных из JSON файлов осуществляется с помощью функции `pd.read_json()`.

#### Синтаксис

```python
pd.read_json(path_or_buf=None, orient='columns', typ='frame', ...)
```

- **path_or_buf:** Путь к файлу, URL или строка JSON.
- **orient:** Определяет, как данные должны быть интерпретированы. Возможные значения:
  - `'split'`: словарь с ключами `index`, `columns`, `data`.
  - `'records'`: список словарей, каждый из которых представляет строку.
  - `'index'`: словарь, где ключи — индексы, значения — словари.
  - `'columns'`: словарь, где ключи — имена столбцов, значения — списки значений.
  - `'values'`: массив, представляющий только значения.
  - `typ`: Тип возвращаемого объекта. `'frame'` (по умолчанию) возвращает DataFrame, `'series'` возвращает Series.

**Пример**

```python
import pandas as pd

# Чтение данных из JSON файла
df = pd.read_json('data.json')
```
В этом примере мы загружаем данные из файла `data.json` в DataFrame. pandas автоматически определяет структуру данных.

#### Чтение с использованием `orient=...`

Если ваши данные представлены как список словарей (где каждый словарь — это запись), вы можете указать параметр `orient='records'`:

```python
data = '''
[
    {"name": "Alice", "age": 30},
    {"name": "Bob", "age": 25}
]
'''

df = pd.read_json(data, orient='records')
```

### Чтение из URL

Вы также можете загружать данные из JSON, доступного по URL. Это удобно для работы с данными, доступными в Интернете.

```python
url = 'https://api.example.com/data.json'
df = pd.read_json(url)
```
Этот подход позволяет напрямую загружать данные из удаленных источников.

### Чтение данных из SQL

Чтение данных из баз данных SQL позволяет интегрировать pandas с системами управления базами данных, такими как SQLite, MySQL, PostgreSQL и другими. Это дает возможность работать с большими объемами данных напрямую из базы данных.

#### Установка соединения

Перед тем как читать данные из SQL, необходимо установить соединение с базой данных. Это можно сделать с помощью библиотеки `sqlalchemy`.

- **Пример установки соединения:**
```python
from sqlalchemy import create_engine

# Создаем соединение с базой данных
engine = create_engine('sqlite:///my_database.db')
```
В этом примере мы создаем соединение с базой данных SQLite. Для других СУБД потребуется указать соответствующий URI.

#### Чтение данных с использованием `pd.read_sql()`

Функция `pd.read_sql()` позволяет выполнять SQL-запросы и загружать результаты в DataFrame.

- **Синтаксис:**
  ```python
  pd.read_sql(sql, con, ...)
  ```

- **Пример:**
```python
from sqlalchemy import text

# Выполняем сложный SQL-запрос
query = text('SELECT * FROM my_table WHERE column1 > :value')
df = pd.read_sql(query, con=engine, params={'value': 10})
```
Здесь мы выполняем SQL-запрос для выбора данных из таблицы `my_table`. Результат запроса автоматически загружается в DataFrame.

# Конспект раздела 4. Запись данных

## 4. Запись данных

### Запись DataFrame в CSV: `to_csv()`

Метод `to_csv()` позволяет сохранить DataFrame в файл формата CSV (Comma-Separated Values). Этот формат широко используется для хранения табличных данных. 

**Синтаксис:**
```python
DataFrame.to_csv(path_or_buf=None, sep=',', na_rep='', float_format=None, header=True, index=True, mode='w', encoding=None, line_terminator=None, quotechar='"', quoting=csv.QUOTE_MINIMAL, escapechar=None, decimal='.', errors='strict', storage_options=None)
```

**Параметры:**
- **path_or_buf**: Путь к файлу или объект, в который будет записан DataFrame.
- **sep**: Символ, используемый в качестве разделителя (по умолчанию - запятая).
- **na_rep**: Значение, заменяющее отсутствующие данные (по умолчанию - пустая строка).
- **header**: Указывает, писать ли заголовки столбцов (по умолчанию - True).
- **index**: Указывает, записывать ли индекс (по умолчанию - True).

**Пример:**
```python
df.to_csv('data.csv', index=False)
```
*Этот код сохранит DataFrame `df` в файл `data.csv`, при этом индекс не будет записан.*

### Запись в Excel: `to_excel()`

Метод `to_excel()` используется для сохранения DataFrame в файл формата Excel (.xlsx). Это удобно, когда данные нужно представить в более структурированном виде с возможностью дальнейшего редактирования в Excel.

**Синтаксис:**
```python
DataFrame.to_excel(excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=False, storage_options=None)
```

**Параметры:**
- **excel_writer**: Путь к файлу или объект ExcelWriter.
- **sheet_name**: Имя листа в Excel (по умолчанию - 'Sheet1').
- **na_rep**: Значение для отсутствующих данных (по умолчанию - пустая строка).
- **header**: Указывает, писать ли заголовки столбцов (по умолчанию - True).
- **index**: Указывает, записывать ли индекс (по умолчанию - True).

**Пример:**
```python
df.to_excel('data.xlsx', sheet_name='Sheet1', index=False)
```
*Этот код сохранит DataFrame `df` в файл `data.xlsx` на листе 'Sheet1', не записывая индекс.*

### Запись в JSON: `to_json()`

Метод `to_json()` позволяет сохранить DataFrame в формате JSON (JavaScript Object Notation), который используется для передачи данных в веб-приложениях.

**Синтаксис:**
```python
DataFrame.to_json(path_or_buf=None, orient='columns', date_format='epoch', double_precision=10, force_ascii=True, lines=False, compression='infer', index=True, indent=None, default_handler=None, storage_options=None)
```

**Параметры:**
- **path_or_buf**: Путь к файлу или объект, в который будет записан DataFrame.
- **orient**: Определяет формат записи (например, 'records', 'columns' и др.).
- **lines**: Указывает, записывать ли данные построчно (по умолчанию - False).

**Пример:**
```python
df.to_json('data.json', orient='records')
```
*Этот код сохранит DataFrame `df` в файл `data.json` в формате JSON, используя ориентацию 'records', что позволяет представлять каждый ряд как отдельный объект.*

### Запись в SQL: `to_sql()`

Метод `to_sql()` позволяет записать данные из DataFrame в базу данных SQL. Это полезно для работы с большими объемами данных, хранения их в реляционных базах данных и выполнения SQL-запросов.

**Синтаксис:**
```python
DataFrame.to_sql(name, con, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None, method=None, **kwargs)
```

**Параметры:**
- **name**: Имя таблицы, в которую будут записаны данные.
- **con**: Объект подключения к базе данных (например, SQLAlchemy).
- **if_exists**: Определяет поведение, если таблица уже существует ('fail', 'replace', 'append').
- **index**: Указывает, записывать ли индекс (по умолчанию - True).

**Пример:**
```python
df.to_sql('table_name', con=engine, if_exists='replace', index=False)
```
*Этот код сохранит DataFrame `df` в таблицу `table_name` в базе данных, заменяя её, если она уже существует, и не записывая индекс.*


